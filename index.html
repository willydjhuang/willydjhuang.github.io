<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Ding-Jiun Huang</title> <meta name="author" content="Ding-Jiun Huang"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%AE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://willydjhuang.github.io/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/cv.pdf">cv</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Ding-Jiun</span> Huang </h1> <p class="desc">B.S. Researcher in Vision and Learning Lab, National Taiwan University</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg?0350c31eae874f50d7c1ba7676e5ed38" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>I’m Ding-Jiun Huang (黃定鈞), a student researcher working in <a href="http://vllab.ee.ntu.edu.tw/" rel="external nofollow noopener" target="_blank">Vision and Learning Lab</a>, advised by ​​Prof. <a href="http://vllab.ee.ntu.edu.tw/ycwang.html" rel="external nofollow noopener" target="_blank">Yu-Chiang Frank Wang</a>, and I am fortunate to have worked with Dr. <a href="https://sunset1995.github.io/" rel="external nofollow noopener" target="_blank">Cheng Sun</a> from NVIDIA Research. My research interests include 3D computer vision, image/video processing and autonomous vehicles.</p> <p>I received my B.S. from Department of <a href="https://www.csie.ntu.edu.tw//?locale=en" rel="external nofollow noopener" target="_blank">Computer Science and Information Engineering</a>, <a href="https://www.ntu.edu.tw/english/" rel="external nofollow noopener" target="_blank">National Taiwan University</a> in 2023, and I had the pleasure to conduct research under the supervision of Prof. <a href="https://www.csie.ntu.edu.tw/~cwlin/" rel="external nofollow noopener" target="_blank">Chung-Wei Lin</a> in my undergraduate researches.</p> </div> <h2>Education</h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 15%"> <img style="width: 80%" src="assets/img/ntu_logo.png"> </th> <td> <h5 id="bs-in-computer-science--information-engineering">B.S. in Computer Science &amp; Information Engineering</h5> <h5 id="national-taiwan-university">National Taiwan University</h5> <p><em>Sep 2019 - June 2023</em></p> <h6 id="overall-gpa-41743-last-60-gpa-41943">Overall GPA: 4.17/4.3, Last-60 GPA: 4.19/4.3</h6> </td> </tr> </table> </div> </div> <h2>Research Experiences</h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 15%"> <img style="width: 80%" src="assets/img/ntu_logo.png"> </th> <td> <h5 id="vision-and-learning-laboratory-national-taiwan-university">Vision and Learning Laboratory, National Taiwan University</h5> <p>Student Researcher, <em>July 2023 - Present</em> <br> <strong>Research topic</strong>: scene reconstruction, super-resolution of radiance field</p> <h5 id="cyber-physical-systems-laboratory-national-taiwan-university">Cyber-Physical Systems Laboratory, National Taiwan University</h5> <p>Student Researcher, <em>July 2022 - June 2023</em> <br> <strong>Research topic</strong>: autonomous vehicles platooning, path planning for autonomous vehicles</p> </td> </tr> <tr> <th scope="row" style="width: 15%"> <img style="width: 80%" src="assets/img/nvidia_logo.svg"> </th> <td> <h5 id="nvidia-research-taiwan">NVIDIA Research Taiwan</h5> <p>Student Researcher (In Collaboration), <em>September 2023 - Present</em> <br> <strong>Research topic</strong>: scene reconstruction, super-resolution of radiance field</p> </td> </tr> <tr> <th scope="row" style="width: 15%"> <img style="width: 80%" src="assets/img/asu_logo.png"> </th> <td> <h5 id="make-programming-simple-laboratory-arizona-state-university">Make Programming Simple Laboratory, Arizona State University</h5> <p>Student Researcher (Remote Collaboration), <em>Feburary 2023 - June 2023</em> <br> <strong>Research topic</strong>: motion planning for autonomous vehicles</p> </td> </tr> <tr> <th scope="row" style="width: 15%"> <img style="width: 80%" src="assets/img/kkcompany.png"> </th> <td> <h5 id="advanced-research-center-kkcompany">Advanced Research Center, <a href="https://www.kkcompany.com/en-us/" rel="external nofollow noopener" target="_blank">KKCompany</a> </h5> <p>Research Engineer Intern, <em>July 2022 - June 2023</em> <br> <strong>Research topic</strong>: image/video enhancement, video quality assessment</p> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/assr-nerf_new.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/assr-nerf_new.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/assr-nerf_new.gif-1400.webp"></source> <img src="/assets/img/publication_preview/assr-nerf_new.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="assr-nerf_new.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="huang2023sbvqa" class="col-sm-7"> <div class="title">ASSR-NeRF: Arbitrary-Scale Super-Resolution on Voxel Grid for High-Quality Radiance Fields Reconstruction</div> <div class="author"> Ding-Jiun Huang, Zi-Ting Chou, Yu-Chiang Frank Wang, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Cheng Sun' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"><em>Preprint (under review)</em></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/assr-nerf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://assr-nerf.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="abstract hidden"> <p>NeRF-based methods reconstruct 3D scenes by building a radiance field with implicit or explicit representations. While existing state-of-the-art methods for 3D scene reconstruction can capture geometry and appearance of a scene accurately, the quality of the rendered novel views is bounded by the training views. On the other hand, single-image super-resolution aims to restore lowresolution (LR) images to high-resolution (HR) counterparts and enhance details as well as textures simultaneously. To improve the rendering quality of a radiance field trained with LR training views, we propose Arbitrary-Scale Super-Resolution NeRF (ASSR-NeRF), a novel framework for super-resolution (SR) of neural radiance field. A voxelbased radiance field is first constructed with training views. Then, an attention-based VoxelGridSR module performs SR directly on the constructed radiance field, instead of the rendered 2D views, to generate finer details and textures in rendered views. Experiments with both quantitative and qualitative comparisons show that our proposed method significantly improves rendering quality.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/sb-vqa_preview.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/sb-vqa_preview.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/sb-vqa_preview.gif-1400.webp"></source> <img src="/assets/img/publication_preview/sb-vqa_preview.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="sb-vqa_preview.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="huang2023sbvqb" class="col-sm-7"> <div class="title">SB-VQA: A Stack-Based Video Quality Assessment Framework for Video Enhancement</div> <div class="author"> Ding-Jiun Huang, Yu-Ting Kao, Tieh-Hung Chuang, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Ya-Chun Tsai, Jing-Kai Lou, Shuen-Huei Guan' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"><em>IEEE/CVF CVPR NTIRE 2023</em></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/sb-vqa.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>In recent years, several video quality assessment (VQA) methods have been developed, achieving high performance. However, these methods were not specifically trained for enhanced videos, which limits their ability to predict video quality accurately based on human subjective perception. To address this issue, we propose a stack-based framework for VQA that outperforms existing state-of-the-art methods on VDPVE, a dataset consisting of enhanced videos. In addition to proposing the VQA framework for enhanced videos, we also investigate its application on professionally generated content (PGC). To address copyright issues with premium content, we create the PGCVQ dataset, which consists of videos from YouTube. We evaluate our proposed approach and state-of-the-art methods on PGCVQ, and provide new insights on the results. Our experiments demonstrate that existing VQA algorithms can be applied to PGC videos, and we find that VQA performance for PGC videos can be improved by considering the plot of a play, which highlights the importance of video semantic understanding.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/platoon_preview.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/platoon_preview.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/platoon_preview.gif-1400.webp"></source> <img src="/assets/img/publication_preview/platoon_preview.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="platoon_preview.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10186667" class="col-sm-7"> <div class="title">Consensus-Based Fault-Tolerant Platooning for Connected and Autonomous Vehicles</div> <div class="author"> Tzu-Yen Tseng, Ding-Jiun Huang, Jia-You Lin, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Po-Jui Chang, Chung-Wei Lin, Changliu Liu' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"><em>IEEE Intelligent Vehicles Symposium 2023</em></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="/assets/pdf/fault_tolerant_platoon.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Platooning is a representative application of connected and autonomous vehicles. The information exchanged between connected functions and the precise control of autonomous functions provide great safety and traffic capacity. In this paper, we develop an advanced consensus-based approach for platooning. By applying consensus-based fault detection and adaptive gains to controllers, we can detect faulty position and speed information from vehicles and reinstate the normal behavior of the platooning. Experimental results demonstrate that the developed approach outperforms the state-of-the-art approaches and achieves small steady state errors and small settling times under scenarios with faults.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%64%6A%68%75%61%6E%67%33%32%32@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://www.linkedin.com/in/ding-jiun-huang-87b0a51b7" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">I am best reached via email. </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Ding-Jiun Huang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>